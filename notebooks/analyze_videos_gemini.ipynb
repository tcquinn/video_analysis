{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e106f095-73fe-468c-9e95-a4c1894f4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae87ab1-fd81-4649-832a-eaef3a0f6be2",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa59a74-9f21-4aae-aae4-bf363a8a221c",
   "metadata": {},
   "source": [
    "### Define output path details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b45725e-97c8-4ea2-9c9e-e129df943264",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_path = Path('./output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a046ca4-f1b0-4f1f-ac83-09949d57f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_extension = 'md'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af111ad3-3782-443e-bb40-abfc8bcc8e82",
   "metadata": {},
   "source": [
    "### Define model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8e9d1f-0a84-4536-8361-89cc12498a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'gemini-2.5-pro-preview-05-06',\n",
    "    'gemini-2.5-flash-preview-05-20',\n",
    "    'gemini-2.0-flash',\n",
    "    'gemini-2.0-flash-lite',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b87803-5f9e-4dda-8dcc-cbbed4285f19",
   "metadata": {},
   "source": [
    "### Define prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30440e2d-3625-4ddc-bbd2-c6aecee5a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "    'lh_prompt': \"\"\"\n",
    "This is a video of a student working on an 8th grade math problem. (1) Create a table summarizing each move the student makes,\n",
    "the skill needed to make that move, whether the student is successful, and what that tells us about possible misconceptions or\n",
    "bugs the student reveals. (2) Summarize the student’s understanding and misconceptions and what they may need more help with,\n",
    "if anything.\n",
    "\"\"\",\n",
    "    'tq_prompt': \"\"\"\n",
    "This video is a screen capture of a student taking a math lesson. Based on the student's interaction with this lesson,\n",
    "what should the teacher do to help this student learn?\n",
    "\n",
    "Consider things like:\n",
    "* How is the student interacting with the lesson? Do they seem engaged? How do they react when they face difficulty?\n",
    "* What concepts and procedures does the student appear to have mastered?\n",
    "* What concepts and procedures does the student struggle with? What appears to be the nature of their misunderstanding?\n",
    "* What appears to be their state of engagement and understanding by the end of this interaction?\n",
    "* Given all of the above, what should the teacher do to help accelerate this student's learning (not just give them the answer)?\n",
    "\n",
    "Please give your response in Markdown format.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1d7cd-499d-4a22-8451-485b26bd6046",
   "metadata": {},
   "source": [
    "### List input videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b734bc8-3f68-4b26-a1a7-49e629de3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = {\n",
    "    'lh_video': {\n",
    "        'path': Path('../videos/Zearn Screen Recording 2025-04-25 at 7.55.09 AM.mp4'),\n",
    "        'duration_minutes': 3.0 + 53/60,\n",
    "        'size_mb': 23.3,\n",
    "    },\n",
    "    'tq_video':  {\n",
    "        'path': Path('../videos/zearn_g8m2l4_brief_confusion.mp4'),\n",
    "        'duration_minutes': 2.0 + 19/60,\n",
    "        'size_mb': 5.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cd099-6cfb-4eef-9b2a-6ecd39be93f1",
   "metadata": {},
   "source": [
    "## Initialize Gemini client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88cbe5b0-f918-4998-9b60-1b9ec5f5705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "if api_key is None:\n",
    "    raise ValueError ('Gemini API key not found in environment variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9015929-3cc2-4d17-80f5-702e846842a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89448da9-f2b0-49e7-aefa-fdc9ad954684",
   "metadata": {},
   "source": [
    "## Upload videos to Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d9fac1-0ba3-4e34-b5b4-469f856b85fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: PROCESSING\n",
      "lh_video: ACTIVE\n",
      "tq_video: PROCESSING\n",
      "tq_video: PROCESSING\n",
      "tq_video: PROCESSING\n",
      "tq_video: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "videos = dict()\n",
    "for video_identifier, video_metadata in video_info.items():\n",
    "    videos[video_identifier] = client.files.upload(file=video_metadata['path'])\n",
    "    while True:\n",
    "        videos[video_identifier] = client.files.get(name=videos[video_identifier].name)\n",
    "        print(f\"{video_identifier}: {videos[video_identifier].state}\")\n",
    "        if videos[video_identifier].state.name == \"ACTIVE\":\n",
    "            break\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d018e-30a4-4040-815e-4191e6dcc640",
   "metadata": {},
   "source": [
    "## Analyze videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea768d8-b0e9-463f-9e4a-4e6b054ac852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: lh_video\n",
      " Prompt: lh_prompt\n",
      "  Model: gemini-2.5-pro-preview-05-06\n",
      "  Model: gemini-2.5-flash-preview-05-20\n",
      "  Model: gemini-2.0-flash\n",
      "  Model: gemini-2.0-flash-lite\n",
      " Prompt: tq_prompt\n",
      "  Model: gemini-2.5-pro-preview-05-06\n",
      "  Model: gemini-2.5-flash-preview-05-20\n",
      "  Model: gemini-2.0-flash\n",
      "  Model: gemini-2.0-flash-lite\n",
      "Video: tq_video\n",
      " Prompt: lh_prompt\n",
      "  Model: gemini-2.5-pro-preview-05-06\n",
      "  Model: gemini-2.5-flash-preview-05-20\n",
      "  Model: gemini-2.0-flash\n",
      "  Model: gemini-2.0-flash-lite\n",
      " Prompt: tq_prompt\n",
      "  Model: gemini-2.5-pro-preview-05-06\n",
      "  Model: gemini-2.5-flash-preview-05-20\n",
      "  Model: gemini-2.0-flash\n",
      "  Model: gemini-2.0-flash-lite\n"
     ]
    }
   ],
   "source": [
    "metadata_list = list()\n",
    "for video_identifier, video in videos.items():\n",
    "    print(f\"Video: {video_identifier}\")\n",
    "    for prompt_identifier, prompt in prompts.items():\n",
    "        print(f\" Prompt: {prompt_identifier}\")\n",
    "        for model in models:\n",
    "                print(f\"  Model: {model}\")\n",
    "                text_prompt_count_tokens_response = client.models.count_tokens(\n",
    "                    model=model,\n",
    "                    contents=prompt,\n",
    "                )\n",
    "                video_prompt_count_tokens_response = client.models.count_tokens(\n",
    "                    model=model,\n",
    "                    contents=video,\n",
    "                )\n",
    "                generate_content_response = client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=[\n",
    "                        videos[video_identifier],\n",
    "                        prompts[prompt_identifier],\n",
    "                    ],\n",
    "                )\n",
    "                output_path = (\n",
    "                    output_directory_path /\n",
    "                    f\"{video_identifier}_{prompt_identifier}_{model}.{output_extension}\"\n",
    "                )\n",
    "                with open(output_path, 'w') as fp:\n",
    "                    fp.write(generate_content_response.text)\n",
    "                metadata = OrderedDict([\n",
    "                    ('video', video_identifier),\n",
    "                    ('prompt', prompt_identifier),\n",
    "                    ('model', model),\n",
    "                    ('video_local_path', str(video_info[video_identifier]['path'])),\n",
    "                    ('video_remote_path', videos[video_identifier].name),\n",
    "                    ('video_duration_minutes', video_info[video_identifier]['duration_minutes']),\n",
    "                    ('video_duration_minutes_returned',int(videos[video_identifier].video_metadata['videoDuration'][:-1])/60.0),\n",
    "                    ('video_size_mb', video_info[video_identifier]['size_mb']),\n",
    "                    ('video_size_mb_returned', videos[video_identifier].size_bytes/1024**2),\n",
    "                    ('prompt_tokens_precalculated', text_prompt_count_tokens_response.total_tokens),\n",
    "                    ('video_tokens_precalculated', video_prompt_count_tokens_response.total_tokens),\n",
    "                    ('prompt_token_count', generate_content_response.usage_metadata.prompt_token_count),\n",
    "                    ('thoughts_token_count', generate_content_response.usage_metadata.thoughts_token_count),\n",
    "                    ('candidates_token_count', generate_content_response.usage_metadata.candidates_token_count),\n",
    "                    ('total_token_count', generate_content_response.usage_metadata.total_token_count),\n",
    "                ])\n",
    "                for prompt_tokens_detail in generate_content_response.usage_metadata.prompt_tokens_details:\n",
    "                    if prompt_tokens_detail.modality == 'TEXT':\n",
    "                        metadata['prompt_tokens_detail_text'] = prompt_tokens_detail.token_count\n",
    "                    elif prompt_tokens_detail.modality == 'VIDEO':\n",
    "                        metadata['prompt_tokens_detail_video'] = prompt_tokens_detail.token_count\n",
    "                    elif prompt_tokens_detail.modality == 'AUDIO':\n",
    "                        metadata['prompt_tokens_detail_audio'] = prompt_tokens_detail.token_count\n",
    "                    else:\n",
    "                        pass\n",
    "                metadata_list.append(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3face419-5b82-43eb-94d5-e4deacd501e7",
   "metadata": {},
   "source": [
    "## Save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dbe672a-83a7-4a67-88fd-b0a58ecb4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_table = pd.DataFrame(metadata_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1077419-ea34-4753-ad96-90f248801760",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = (\n",
    "    datetime.datetime\n",
    "    .now(tz=datetime.timezone.utc)\n",
    "    .strftime('%Y%m%d_%H%M%S')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c323283-cba0-4807-aaa4-25a72d45a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_table.to_pickle(output_directory_path / f\"gemini_analysis_metadata_{timestamp}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7d7cbfd-8f22-4740-a044-578c7e07ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_table.to_csv(output_directory_path / f\"gemini_analysis_metadata_{timestamp}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
